\section{Interpolation: Interpolation}
Given a set of x, f(x) pairs (e.g., in a pair of arrays
xarr,yarr), and given an x, use interpolation to find y.

There are general purpose approaches, and also some
specialized to general polynomials and others specialized to 
orthogonal approximatrixions
such as Chebyshev approximatrixions.  Here we consider only the
general cases.

The first step is to find the closest xa value as a start
point.  Then one can interpolationolate from that value and its
yarr pair.  We can do linear, quadtraic, nth order
polynomial interpolations.

\subsection*{interpolation\_linear}
Pretty straightforward.  I found it giving errors of 1--5\%
for a 10-value sin table, and 0.01\% error for a 100-value
sin table.

\subsection*{interpolation\_polynomial}
NR92 describes it on pg 109.  In the basic P form, the
result is a polynomial with n terms, of which all but 1
(e.g., k) go to zero.  So one then has:
\begin{equation}
     P(x)=\frac{(x-x_1)(x-x_2) \cdots (x-x_n)}
                 {((x_k-x_1)(x_k-x_2) \cdots (x_k-x_n))y_k}
\end{equation}
So we need to collect the numerator and we need to find the
right k.  Eqn 3.1.3 computes these on the fly, col by col.
According to several other books, polynomial interpolation
is numerically unstable.  But NR92's suggests improvements, based on
capturing differences (NR92's eqn 3.1.5):
\begin{eqnarray}
  D_{m+1,i} & = & \frac{(x_{i+m+1}-x)(C_{m,i+1}-D_{m,i})}{x_i-x_{i+m+1}}\\
  C_{m+1,i} & = & \frac{(x_{i}    -x)(C_{m,i+1}-D_{m,i})}{x_i-x_{i+m+1}}
\end{eqnarray}


Note that the recurrence
slides the whole equilateral triangle into a right triangle
form, with the {\em first} item in each col placed in the C,D
arrays at index 1.  Thus as we go along the cols, the number
of invalid values grows from the bottom of the arrays.

Once we have the full col worth of C and D values per the
recurrence, we select which one to use.  NR92 uses a cryptic
formula:
\begin{verbatim}
     if 2*ns < (n-m) then
       dy=c[ns+1]
     else
       dy=d[ns--]
     end
\end{verbatim}

Here, ns is the index aligned with the input x.  Note that
after using d we decrement ns.  That is, we move further
toward the top of the array.  But after using c we stay put.
We do momentarily peek further down the array as c[ns+1],
but ns stays the same.

The next thing to notice is that n-m is the total number of
new values in this col.  [From there to n we have old data
from previous cols.]  ns should be centered in this set of
values, which are offset from 1.  So ns should be
$\approx ((n-m)-1)/2$.  NR92 replaces the div with a mul by using
$2 \mbox{ns} \approx (n-m)$.

What if ns is too small?  That means we are too far
toward the top of the array.  That will be alright once we
go to the next col, because the array will slide up and ns
will be correctly centered again.  But if we are too far
down, we need to decrement ns.  Also, if we are dead on, we
still need to decrement in order to get centered for the
next col.

The remaining problem is to understand 3.1.5.  First we note
that $m$ means the old column, and $m+1$ means the new
column we are currently generating.  But the easier way to
do this is to think of the righthand side c and d as m-1 and
the lefthand side as m.  Then as we do the big loop for the
columns (m=1,2,...n-1), we just need to use the old c and d,
and create the new ones in situ.  With this understanding,
x[i+m+1] means the x[i+m] as seen for the new column.

Next, note that we have a common factor of $(C_{m,i+1}-
D{m,i})/(x_i-x_{i+m+1})$.  Before we compute that, we need to
check to see if the denominator is zero.

Next, we need to know how many of the cells are valid for a
given col.  We start with n cells, and lose one every time
we calc a new col.  NR92 recalcs this as n-m every loop.  I
have pulled it out as col\_n.  Mainly I did it to make it
more readable, but it just might be faster too.

Once we have the loops running m=1\dots n-1 and i=1\dots col\_n, we
need to access the right cells.  I made c and d easier by
writing them to 0..n arrays and just using the 1\dots n part.
xa is still in the 0\dots n-1 form, so I have to replace all {\tt i}
with {\tt i-1}.  I capture the resulting xa accesses as xi for
x[i] in 3.1.5 and xim1 for x[i+m+1] in 3.1.5.

To do offsetting (e.g., to do 4 point interpolation out of a much
larger table): The idea is to pass start and len with
defaults of 0.  If $len \ne 0$ then we know we need to do
partial access.  From there, we use symbolic start and end
values to keep track of indexes. C and D still live in their
1\dots n world, but we now have to offset the xa[] accesses by
the xn1 value (which is usually 0).

The relative error on even a 10-value sin table is
impressive (on the order of 1.0e-8).  It may be complex, but
it sure does its job.
