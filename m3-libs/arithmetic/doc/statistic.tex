\section{Statistic: Statistics}
\subsection*{describe}
This analysis follows from NR92, pp 610--613.  However, the basic definitions
are common to all statistics books.  The key insight from NR92 (and not
original there), is the 2-pass corrected calculation of variance.

To rehearse the equations:
\begin{eqnarray}
  \mbox{mean} & = & \mbox{avg} = \overline{x} = 
                    \frac{1}{N}\sum_{j=1}^{N}x_j\\
  \mbox{avg dev} & = & \frac{1}{N}\sum_{j=1}^{N}|x_j-\overline{x}|\\
  \mbox{var} & = & \frac{1}{N}\left [ \sum_{j=1}^{N}(x_j-\overline{x})^2
                   - \frac{1}{N} \left [ \sum_{j=1}^{N}(x_j
                       -\overline{x})\right]^2\right]\\
  \mbox{std dev} & =& \sigma  =  \sqrt{\mbox{var}}\\
  \mbox{skew} & = & \frac{1}{N}\sum_{j=1}^{N} 
                    \left [\frac{x_j-\overline{x}}{\sigma}\right]^3\\
  \mbox{kurt} & = & \left\{\frac{1}{N}\sum_{j=1}^{N} 
                    \left [\frac{x_j-\overline{x}}{\sigma}\right]^4
                    \right\} - 3
\end{eqnarray}
We also pick up min and max values during the first pass.

\subsection*{ttest}
This is Student's t-test.  The idea is to find if the means of 
two samples are the same and how likely that is to be due to chance.

Again, we follow NR92, pg 616, but the formula
is common:
\begin{eqnarray}
s_D & =  & \sqrt{\frac{\sum_{i\in A}(x_i-\overline{x_A})^2 
                      +\sum_{i\in B}(x_i-\overline{x_B})^2}
                      {N_A+N_B-2}
                 \left(\frac{1}{N_A}+\frac{1}{N_B}\right)
                }\\
t & = & \frac{\overline{x_A}-\overline{x_B}}{s_D}
\end{eqnarray}

There are a number of ways 
to compute the probability that this was due to chance.  Following
NR92, we use:
\begin{eqnarray}
    I_x(a,b) & = & \mbox{incomplete Beta function} 
               = \frac{B_x(a,b)}{B(a,b)}
               = \frac{1}{B(a,b)}\int_0^xt^{a-1}(1-t)^{b-1}dt\\
    \nu & = & \mbox{degrees of freedom}\\
    A(t|\nu) & = & \mbox{probability that t could be that small by chance}\\
             & = & 1- I_{\frac{\nu}{\nu_t^2}}(\frac{\nu}{2},\frac{1}{2})
\end{eqnarray}

\subsection*{ftest}
This is the F-test.  The idea is to find if the variances of two
samples are the same, and how likely that is to be due to chance.
\begin{equation}
 F = \mbox{var1} / \mbox{var2}
\end{equation}
var1 and var2 are chosen so the ratio comes out  $>1$.  There are a number of ways 
to compute the probability that this was due to chance.  Following
NR92, we use:
\begin{eqnarray}
    \nu_1,\nu_2 & = & \mbox{degrees of freedom}\\
    Q(F|\nu_1,\nu_2) & = & \mbox{probability that F could be that small by chance}\\
             & = & I_{\frac{\nu_2}{\nu_2+\nu_1F}}
                     (\frac{\nu_2}{2},\frac{\nu_1}{2})
\end{eqnarray}


\subsection*{chi\_sqr1}
$\chi^2$ tests whether or not a binned distribution is as expected.
NR92 (pg 621, eqn 14.3.1 and pg 221, eqn 6.2.19) gives:
\begin{eqnarray}
  N_i & = & \mbox{number of items in bin i}\\
  n_i & = & \mbox{number of items expected in bin i}\\
  \chi^2 & = & \sum_i\frac{(N_i-n_i)^2}{n_i}\\
  Q(\chi^2|\nu) & = & Q(\frac{\nu}{2},\frac{\chi^2}{2})
         = \mbox{incomplete gamma function P}
\end{eqnarray}

Krey88, pg 1280 says the bins should have $\ge 5$ items each.  We'll
raise an exception if that is not met.

\subsection*{chi\_sqr2}
This version of $\chi^2$ checks similarlity between two actual
collecitons of bins (not just an actual and an expected).
NR92, pg 622, give sthe equaiton eqn 14.3.2:
\begin{eqnarray}
  R_i & = & \mbox{number of items in R's bin i}\\
  S_i & = & \mbox{number of items in S's bin i}\\
  \chi^2 & = & \sum_i\frac{(R_i-S_i)^2}{R_i+S_i}\\
  Q(\chi^2|\nu) & = & Q(\frac{\nu}{2},\frac{\chi^2}{2})
         = \mbox{incomplete gamma function P}
\end{eqnarray}

