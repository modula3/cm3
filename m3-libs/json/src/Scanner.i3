(* Copied from M3Scanner.i3 and modified for json *)

INTERFACE Scanner;

IMPORT Rd;

TYPE
  T = OBJECT
    token        : CARDINAL  := TK_Comment;
    start        : CARDINAL  := 0;
    length       : CARDINAL  := 0;
    offset       : CARDINAL  := 0;
    line         : CARDINAL  := 0;
    column       : CARDINAL  := 0;
    msg          : TEXT      := NIL;
    buffer       : Buf       := NIL;
  METHODS
    next ();
    toText (): TEXT;
    className (tk: INTEGER): TEXT;
  END;

  Buf = BRANDED "JsonScanner.Buf" REF ARRAY OF CHAR;

TYPE
  Default <: T OBJECT METHODS
    initFromRd  (source        : Rd.T;
                 skip_comments := TRUE;
                 split_pragmas := TRUE): T;
    initFromBuf (buf           : Buf;
                 skip_comments := TRUE;
                 split_pragmas := TRUE): T;
  END;

TYPE
  TK = [TK_Comment .. TK_False];

CONST (* Token classes returned by a "Default" scanner. *)
  TK_Comment = 0;          TK_EOF = 1;              TK_Error = 2;

  (* lexical classes with variable literals *)
  TK_Ident = 3;            TK_Card_const = 4;       TK_Real_const = 5;
  TK_Text_const = 6;

  (* operators *)
  TK_Comma = 7;            TK_L_bracket = 8;        TK_L_brace = 9;
  TK_R_bracket = 10;       TK_R_brace = 11;         TK_Colon = 12;

  (* reserved words *)
  TK_Null = 13;            TK_True = 14;            TK_False = 15;


CONST
  First_Literal  = TK_Ident;
  Last_Literal   = TK_Text_const;
  First_Operator = TK_Comma;
  Last_Operator  = TK_Colon;
  First_Keyword  = TK_Null;
  Last_Keyword   = TK_False;

CONST
  TokenName = ARRAY TK OF TEXT {
    "**COMMENT**", "**EOF**", "**ERROR**",

    "<id>", "<cardinal>", "<real>", "<text>",
    ",",  "[",  "{",  "]",  "}",  ":",

    "null", "true", "false"  };

END Scanner.

(*
An "Scanner.T", or scanner, parses a stream of characters and
returns a stream of JSON tokens. If "s" is a scanner, each
call "s.next()" sets the values of "s"'s fields to correspond to
the next token in the stream.

The fields of a scanner are not to be modified by its client.

"s.token" is the class of the token.  It is one of the
"TK_" values defined above.  Subtypes of "Scanner.T" may
define additional values.

In "s.buffer[s.start .. s.start+s.length-1]" are the characters
that comprise the token.

"s.offset" is the character offset of the token relative to the
beginning of the stream.  The first character of the stream is
at offset zero.

"s.line" is the line where the token occured relative
to the beginning of the stream.   The first line is one.

"s.column" is the character offset of the beginning of the token
within the line that contains it.  The first column is zero.

"s.buffer" contains the source being scanned.  Modifying its contents
may perturb the token stream or cause a checked runtime error.

"s.msg" describes the error that caused the "Error" token to be
returned.

"s.toText()" returns the TEXT value of current token.

If "tk" is a token class generated by "s", "s.className(tk)" returns
string identifing that class.  Otherwise, "NIL" is returned.

The scanner returned by "NEW(Default).initFromRd(rd)" will read the
entire contents of "rd" into its buffer and initialize
the scanner as a zero-length comment at offset zero.

The scanner returned by "NEW(Default).initFromBuf(buf)" will use
"buf" as its buffer and initialize the scanner as a zero-length
comment at offset zero.

If "skip_comments" is "TRUE", outer-level comments will be returned
as tokens.  Otherwise, comments are ignored.

If "split_pragmas" is "TRUE", the contents of pragmas will be scanned
and returned as a stream of tokens between "Begin_pragma" and
"End_pragma" tokens.  If "split_pragmas" is false, the entire pragma
is returned in a single "Begin_pragma" token.
*)
